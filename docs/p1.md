# Project 1: Threads

## Preliminaries

> Fill in your name and email address.

Chin Wang <wangfiox@gmail.com>

> If you have any preliminary comments on your submission, notes for the
> TAs, please give them here.

> Please cite any offline or online sources you consulted while
> preparing your submission, other than the Pintos documentation, course
> text, lecture notes, and course staff.

## Alarm Clock

#### DATA STRUCTURES

> A1: Copy here the declaration of each new or changed struct or struct member, global or static variable, typedef, or enumeration.
> Identify the purpose of each in 25 words or less.

```c
static struct lock timer_sleep_lock;  // å¯èƒ½å¤šçº¿ç¨‹è°ƒç”¨ timer_sleep, æ‰€ä»¥éœ€è¦é”
static struct list timer_sleep_list;  // é“¾è¡¨, é‡Œé¢å­˜æ”¾çš„æ˜¯ ä¸€æ’ semaphore, å¹¶åœ¨ timer_sleep_tick ä¸­ sema_up

struct timer_sleep_elem {
  struct list_elem elem;
  int64_t start;
  int64_t ticks;
  struct semaphore sema;
};

void timer_sleep(int64_t ticks) {
  int64_t start = timer_ticks();

  ASSERT(intr_get_level() == INTR_ON);

  struct timer_sleep_elem tse;
  tse.start = start;
  tse.ticks = ticks;
  sema_init(&tse.sema, 0);

  lock_acquire(&timer_sleep_lock);
  list_push_back(&timer_sleep_list, &tse.elem);
  lock_release(&timer_sleep_lock);

  sema_down(&tse.sema);

}

static void timer_sleep_tick(void) {
  for (struct list_elem *e = list_begin(&timer_sleep_list); e != list_end(&timer_sleep_list); e = list_next(e)) {
    struct timer_sleep_elem *tse = container_of(e, struct timer_sleep_elem, elem);
    if (timer_elapsed(tse->start) >= tse->ticks) {
      sema_up_intr(&tse->sema);
      list_remove(e);
    }
  }
}
```

#### ALGORITHMS

> A2: Briefly describe what happens in a call to timer_sleep(),
> including the effects of the timer interrupt handler.

åˆå§‹åŒ– semaphore, åˆå§‹åŒ–é“¾è¡¨èŠ‚ç‚¹, å¹¶åŠ å…¥åˆ°é“¾è¡¨ä¸­. ç„¶å sema_down.

> A3: What steps are taken to minimize the amount of time spent in
> the timer interrupt handler?

å¯ä»¥ç”¨æœ€å°å †, ä½†æ˜¯æˆ‘æ²¡æœ‰ç”¨.

#### SYNCHRONIZATION

> A4: How are race conditions avoided when multiple threads call
> timer_sleep() simultaneously?

Lock the timer_sleep_list when adding the element.

> A5: How are race conditions avoided when a timer interrupt occurs
> during a call to timer_sleep()?

ä¼¼ä¹å¹¶æ²¡æœ‰æ•°æ®ç«äº‰, å› ä¸º timer_interrupt -> timer_sleep_tick çš„æ—¶å€™, å…³ä¸­æ–­, è¿™ä¸ªæ—¶å€™å¯ä»¥ä¿è¯ timer_sleep_list ä¸ä¼šè¢«å…¶ä»–çº¿ç¨‹ä¿®æ”¹.
å½“ç„¶è¿™ä¸ªå‡è®¾æ˜¯: åªæœ‰ä¸€ä¸ª cpu; (æˆ‘è¿™é‡Œæš‚æ—¶æ²¡æœ‰è€ƒè™‘ å¤š cpu çš„æƒ…å†µ)
å¦‚æœæœ‰å¤šä¸ª cpu, é‚£ä¹ˆå¯èƒ½ä¼šå‘ç”Ÿ: ä¸€ä¸ª cpu åœ¨ timer_sleep_tick ä¸­éå†é“¾è¡¨, å¦ä¸€ä¸ª cpu åœ¨ timer_sleep ä¸­å°†å…ƒç´ åŠ å…¥é“¾è¡¨çš„æƒ…å†µå‘ç”Ÿ. è¿™ä¸ªæ—¶å€™ç¡®å®éœ€è¦è‡ªæ—‹é”.

#### RATIONALE

> A6: Why did you choose this design? In what ways is it superior to
> another design you considered?

è¿™å°±æ˜¯ä¸€ä¸ª: ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å‹. æˆ‘æ˜¯ç”¨ semaphore å®ç°çš„.
å½“ç„¶, ä¹Ÿå¯ä»¥ä½¿ç”¨æ¡ä»¶å˜é‡æ¥å®ç°.

## Priority Scheduling

#### DATA STRUCTURES

> B1: Copy here the declaration of each new or changed struct or struct member, global or static variable, typedef, or enumeration.
> Identify the purpose of each in 25 words or less.

```c
struct lock {
  // ...
  struct list_elem elem;      /**< the elem in thread->locks */
};

struct thread {
  // ...
  int64_t last_sched; /**< last schedule time. */

  /////////////////////////////////////// priority donation
  int before_donated_priority; /**< before donated priority. */
  bool donated;                /**< Whether the thread is donated. */
  struct list locks;
  // ...
};

static int64_t last_sched(void) {
  static int64_t _data = 0;
  enum intr_level old_level;
  old_level = intr_disable();
  int64_t ret = _data++;
  intr_set_level(old_level);
  return ret;
}
```

- last_sched ç”¨äºè®°å½•: ä¸Šä¸€æ¬¡è°ƒåº¦çš„æ—¶é—´, è¿™æ˜¯ä¸€ä¸ªæ—¶é—´æˆ³. è™½è¯´æ˜¯ priority-schedule, ä½†æ˜¯å¯¹äºç›¸åŒçš„ priority, éœ€è¦ round-robin schedule. æ‰€ä»¥éœ€è¦è¿™ä¸ªæ—¶é—´æˆ³æ¥è®°å½•.
- struct list locks: ç”¨äºè®°å½•: å½“å‰çš„çº¿ç¨‹æ‹¥æœ‰å“ªäº› ğŸ”, lock_release å, priority éœ€è¦é‡æ–°è®¡ç®—.
- donated: ç”¨äºè®°å½•æ˜¯å¦å‘ç”Ÿäº† priority donation. åœ¨ lock_acquire ä¸­ set; åœ¨ lock_release ä¸­ clear. åœ¨ thread_set_priority ä¸­ä½¿ç”¨.
- before_donated_priority: ç”¨äºè®°å½•: å‘ç”Ÿ priority donation ä¹‹å‰çš„ priority.

> B2: Explain the data structure used to track priority donation.
> Use ASCII art to diagram a nested donation. (Alternately, submit a
> .png file.)

![nested donation](image/nested.png)

#### ALGORITHMS

> B3: How do you ensure that the highest priority thread waiting for
> a lock, semaphore, or condition variable wakes up first?

```c
static struct thread *sema_pop_max_priority_thread(struct list *list) {
  struct list_elem *elem = list_max(list, sema_less_func, NULL);
  ASSERT(elem != NULL);
  list_remove(elem);
  elem->next = NULL;
  elem->prev = NULL;
  return container_of(elem, struct thread, elem);
}
```

```c
if (!list_empty(&sema->waiters)) {
  struct thread *t = sema_pop_max_priority_thread(&sema->waiters);
  ASSERT(t != NULL);
  thread_unblock(t);
}
```

> B4: Describe the sequence of events when a call to lock_acquire()
> causes a priority donation. How is nested donation handled?

```c
void lock_acquire(struct lock *lock) {
  struct thread *cur = thread_current();
  struct thread *holder = lock->holder;
  if (holder != NULL) {                      // ğŸ” è¢«å ç”¨
    if (holder->priority < cur->priority) {  // ä¼˜å…ˆçº§åè½¬
      priority_donate(holder, cur->priority);
    }
  }
  sema_down(&lock->semaphore);  // ---------- è¿›å…¥ä¸´ç•ŒåŒº ----------
  lock->holder = thread_current();
  thread_push_lock(cur, lock);
}
```

```py
def priority_donate(holder, pri):
    update holder's priority with pri
    if holder is blocked:
        update the holder's holder's priority with pri recursively
```

if holderA is blocked, it means that the holderA is in the sema->waiters,
so we can find the holderB which is the owner of the sema.
then update holderB's priority with pri recursively.

however, if the user program who is a noob, wrote a deadlock code,
which would cause the infinite recursion, making the kernel panic.
we should have a mechanism to detect the loop of the holder chain.
I use a list as a stack to record the holder chain.
if the holder is already in the list, then we find the loop and truncate the recursion.

> B5: Describe the sequence of events when lock_release() is called
> on a lock that a higher-priority thread is waiting for.

```c
void lock_release(struct lock *lock) {
  thread_pop_lock(lock->holder, lock);
  int next_pri = next_priority(lock);
  if (next_pri == -1) {
    next_pri = lock->holder->before_donated_priority;
    lock->holder->donated = false;
  }
  lock->holder->priority = next_pri;
  lock->holder = NULL;        // clear holder
  sema_up(&lock->semaphore);  // ---------- é€€å‡ºä¸´ç•ŒåŒº ----------
}
```

the next_priority is the maximum priority, the waiter who is blocked by the lock holding by the current thread.
If there is no waiter, indicating that the donation is over, then we clear the donated flag, and set the priority to the before_donated_priority.

However, another schema we should consider is that when donation happens,
the current thread called thread_set_priority, if the new_priority is lower than the priority of the current thread, which is being donated.
we should only update the before_donated_priority, not the priority, and not yield the cpu.

```c
int thread_set_priority(int new_priority) {
  struct thread *cur = thread_current();
  int old_priority = cur->priority;
  cur->before_donated_priority = new_priority;
  if (cur->donated) {
    if (old_priority < new_priority) {
      cur->priority = new_priority;
    }
  } else {
    cur->priority = new_priority;
    if (new_priority < old_priority) {
      if (!list_empty(&ready_list)) {
        struct thread *first = container_of(list_max(&ready_list, ready_list_less_func, NULL), struct thread, elem);
        ASSERT(cur != first);  // ä¸å¯èƒ½: æ—¢ RUNNING åˆ READY
        if (cur->priority < first->priority) {
          thread_yield();
        }
      }
    }
  }
  return old_priority;
}
```

#### SYNCHRONIZATION

> B6: Describe a potential race in thread_set_priority() and explain
> how your implementation avoids it. Can you use a lock to avoid
> this race?

I did not consider this race. So sad.

#### RATIONALE

> B7: Why did you choose this design? In what ways is it superior to
> another design you considered?

æˆ‘åŸæœ¬æƒ³ç€æ˜¯: lock ä¸­è®°å½•æœ€å¤§å€¼çš„, ä½†æ˜¯è¿™è€ƒè™‘åˆ°è®¸å¤šé—®é¢˜: priority ä¼šå› ä¸º donation è€Œæ”¹å˜,
å¹¶ä¸”è¿˜ä¼šæœ‰: thread_set_priority çš„æƒ…å†µ. è¿™éœ€è¦ç»´æŠ¤ lock çš„æœ€å¤§å€¼, è¿™å¾ˆéº»çƒ¦, ä¸å¦‚åœ¨ lock_release ä¸­è®¡ç®— maximum priority.

## Advanced Scheduler

#### DATA STRUCTURES

> C1: Copy here the declaration of each new or changed struct or struct member, global or static variable, typedef, or enumeration.
> Identify the purpose of each in 25 words or less.

```c
struct thread {
  // ...
  int nice;
  fixed1714_t recent_cpu;
};

static fixed1714_t *__load_avg(void) {
  static fixed1714_t _data = {._raw = 0};  // init with 0 at boot
  return &_data;
}

static fixed1714_t load_avg(void) { return *__load_avg(); }

typedef union {
  int32_t _raw;
  struct {
    int32_t fraction : FRACTION_BITS;
    int32_t integer : INTEGER_BITS;
    int32_t sign : 1;
  };
} fixed1714_t;
```

- fixed1714_t : 17.14 å®šç‚¹æ•°
- load_avg : cpu å¯åŠ¨ä»¥æ¥çš„ load average.
- nice : thread çš„ nice å€¼.
- recent_cpu : æœ€è¿‘ cpu çš„ä½¿ç”¨æ—¶é—´.

nice, recent_cpu å¯ä»¥ç”¨äºè®¡ç®— priority. priority ç”¨äºè°ƒåº¦, scheduler é‡‡ç”¨ä¼˜å…ˆçº§è°ƒåº¦.
mlfq å®é™…ä¸Šå¹¶ä¸æ˜¯å¤šä¸ªé“¾è¡¨, åªæœ‰ä¸€ä¸ªé“¾è¡¨, ä½†æ˜¯å¯ä»¥é€šè¿‡ priority æ¥æ¨¡æ‹Ÿå¤šçº§.
recent_cpu ç”¨äºè®¡ç®— priority, ä¸€æ®µæ—¶é—´å, æ ¹æ® load_avg è®¡ç®— recent_cpu.
åœ¨ cpu ä¸Šçš„æ—¶é—´è¶Šå¤š, recent_cpu è¶Šå¤§, é‚£ä¹ˆ priority è¶Šå°, ç›¸å½“äºæ˜¯ç§»åŠ¨åˆ°äº†ä½çº§çš„é˜Ÿåˆ—ä¸­.

#### ALGORITHMS

> C2: How is the way you divided the cost of scheduling between code
> inside and outside interrupt context likely to affect performance?

#### RATIONALE

> C3: Briefly critique your design, pointing out advantages and
> disadvantages in your design choices. If you were to have extra
> time to work on this part of the project, how might you choose to
> refine or improve your design?

å¦‚æœæˆ‘è¦æ”¹è¿›, æˆ‘å¯èƒ½ä¼šæ‰“ç®—ä½¿ç”¨ cfs è°ƒåº¦ç®—æ³•.

> C4: The assignment explains arithmetic for fixed-point math in
> detail, but it leaves it open to you to implement it. Why did you
> decide to implement it the way you did? If you created an
> abstraction layer for fixed-point math, that is, an abstract data
> type and/or a set of functions or macros to manipulate fixed-point
> numbers, why did you do so? If not, why not?

æˆ‘è‡ªå®šä¹‰äº†ä¸€ä¸ªæ•°æ®ç±»å‹ fixed1714_t æ¥è¡¨ç¤º 17.14 ä½çš„å®šç‚¹æ•°.
æˆ‘ç¡®å®æä¾›äº†ä¸€ä¸ª abstraction layer æ¥æ“ä½œ fixed1714_t.
ä»–çš„ + - \* / éƒ½å¾—é€šè¿‡å‡½æ•°æ¥æ“ä½œ. å¦‚æœæ˜¯ç”¨ C++ çš„è¯, å¯ä»¥é‡è½½è¿ç®—ç¬¦.
è¿™æ ·åšçš„å¥½å¤„æ˜¯: æˆ‘åé¢å…¶å®å¯ä»¥æ¢ä¸åŒçš„å®šç‚¹æ•°æ–¹æ³•, æ¯”æ–¹è¯´ 16.16 ä½çš„å®šç‚¹æ•°, åªéœ€è¦ä¿®æ”¹åº“çš„ä»£ç å³å¯.
